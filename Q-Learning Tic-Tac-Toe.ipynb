{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train the Q Learner?(Y/N)Y\n",
      "How Many Games of Self-Play?500000\n",
      "Iterations: 20000, X_Wins: 43.49%, O_Wins: 44.08%, Draws%: 12.43% \n",
      "Iterations: 40000, X_Wins: 43.68%, O_Wins: 43.37%, Draws%: 12.95% \n",
      "Iterations: 60000, X_Wins: 43.88%, O_Wins: 43.45%, Draws%: 12.67% \n",
      "Iterations: 80000, X_Wins: 43.48%, O_Wins: 43.80%, Draws%: 12.72% \n",
      "Iterations: 100000, X_Wins: 43.69%, O_Wins: 43.48%, Draws%: 12.83% \n",
      "Iterations: 120000, X_Wins: 43.38%, O_Wins: 44.09%, Draws%: 12.53% \n",
      "Iterations: 140000, X_Wins: 43.45%, O_Wins: 43.45%, Draws%: 13.11% \n",
      "Iterations: 160000, X_Wins: 43.41%, O_Wins: 43.87%, Draws%: 12.72% \n",
      "Iterations: 180000, X_Wins: 43.23%, O_Wins: 43.83%, Draws%: 12.95% \n",
      "Iterations: 200000, X_Wins: 43.94%, O_Wins: 43.36%, Draws%: 12.70% \n",
      "Iterations: 220000, X_Wins: 43.61%, O_Wins: 43.42%, Draws%: 12.97% \n",
      "Iterations: 240000, X_Wins: 44.07%, O_Wins: 43.31%, Draws%: 12.61% \n",
      "Iterations: 260000, X_Wins: 42.97%, O_Wins: 44.22%, Draws%: 12.81% \n",
      "Iterations: 280000, X_Wins: 43.62%, O_Wins: 43.92%, Draws%: 12.46% \n",
      "Iterations: 300000, X_Wins: 43.53%, O_Wins: 43.99%, Draws%: 12.47% \n",
      "Iterations: 320000, X_Wins: 43.53%, O_Wins: 43.63%, Draws%: 12.83% \n",
      "Iterations: 340000, X_Wins: 43.95%, O_Wins: 43.27%, Draws%: 12.78% \n",
      "Iterations: 360000, X_Wins: 44.39%, O_Wins: 43.33%, Draws%: 12.28% \n",
      "Iterations: 380000, X_Wins: 43.62%, O_Wins: 43.58%, Draws%: 12.80% \n",
      "Iterations: 400000, X_Wins: 44.02%, O_Wins: 43.41%, Draws%: 12.56% \n",
      "Iterations: 420000, X_Wins: 44.10%, O_Wins: 43.59%, Draws%: 12.30% \n",
      "Iterations: 440000, X_Wins: 43.29%, O_Wins: 44.28%, Draws%: 12.43% \n",
      "Iterations: 460000, X_Wins: 44.28%, O_Wins: 43.41%, Draws%: 12.31% \n",
      "Iterations: 480000, X_Wins: 43.72%, O_Wins: 43.48%, Draws%: 12.80% \n"
     ]
    }
   ],
   "source": [
    "########\n",
    "## @author Vaibhav Bhilare\n",
    "## @copyright 2017, Vaibhav Bhilare\n",
    "## Application of Q-Learning to teach an agent to play Tic-Tac-Toe from scratch\n",
    "########\n",
    "\n",
    "## Imports\n",
    "import random\n",
    "import operator\n",
    "import pickle\n",
    "\n",
    "## Class for Game\n",
    "class TicTacToe:\n",
    "    def __init__(self, playerX, playerO):\n",
    "        self.board = [' ']*9\n",
    "        self.playerX, self.playerO = playerX, playerO\n",
    "        self.playerX_turn = random.choice([True, False])\n",
    "\n",
    "    def Game(self,X_Wins,O_Wins,Game_Type):\n",
    "        self.playerX.Character('X')\n",
    "        self.playerO.Character('O')\n",
    "        while True:\n",
    "            if self.playerX_turn:\n",
    "                player, char, other_player = self.playerX, 'X', self.playerO\n",
    "            else:\n",
    "                player, char, other_player = self.playerO, 'O', self.playerX\n",
    "            if player.Player_Type == \"human\":\n",
    "                self.display_board()\n",
    "            if Game_Type=='Q_Table':  ## Q-Table Game\n",
    "                space = player.move(self.board,char)\n",
    "            elif Game_Type=='Neural_Network':  ## Neural Network Game\n",
    "                space = player.move_NN(self.board,char)\n",
    "            if self.board[space-1] != ' ':  ## Illegal move\n",
    "                player.reward(-99, self.board)\n",
    "                return X_Wins,O_Wins\n",
    "                break\n",
    "            self.board[space-1] = char\n",
    "            if self.player_wins('X'):  ## X Wins the Game\n",
    "                X_Wins=X_Wins+1\n",
    "                player=self.playerX\n",
    "                player.reward(1, self.board)  ## +1 Reward for Winning\n",
    "                other_player.reward(-1, self.board)\n",
    "                return X_Wins,O_Wins\n",
    "                break\n",
    "            elif self.player_wins('O'):  ## O Wins the Game\n",
    "                O_Wins=O_Wins+1\n",
    "                player=self.playerO\n",
    "                player.reward(1, self.board)\n",
    "                other_player.reward(-1, self.board)  ## -1 Reward for losing\n",
    "                return X_Wins,O_Wins\n",
    "                break\n",
    "            if self.board_full():  ## Draw\n",
    "                player=self.playerX\n",
    "                player.reward(0, self.board)  ## 0 Reward for Draw\n",
    "                other_player.reward(0, self.board)\n",
    "                if Print_Winner==True:\n",
    "                    self.display_board()\n",
    "                    print('Draw!')\n",
    "                return X_Wins,O_Wins\n",
    "                break\n",
    "            other_player.reward(0, self.board)\n",
    "            self.playerX_turn = not self.playerX_turn\n",
    "\n",
    "    def player_wins(self, char):\n",
    "        for a,b,c in [(0,1,2), (3,4,5), (6,7,8),\n",
    "                      (0,3,6), (1,4,7), (2,5,8),\n",
    "                      (0,4,8), (2,4,6)]:\n",
    "            if char == self.board[a] == self.board[b] == self.board[c]:\n",
    "                if Print_Winner==True:\n",
    "                    self.display_board()\n",
    "                    print('Player {} Wins!'.format(char))\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def board_full(self):\n",
    "        return not any([space == ' ' for space in self.board])\n",
    "\n",
    "    def display_board(self):\n",
    "        Row = \" {} | {} | {}\"\n",
    "        Column = \"\\n-----------\\n\"\n",
    "        print((Row + Column + Row + Column + Row).format(*self.board))\n",
    "\n",
    "\n",
    "class Player(object):\n",
    "    def __init__(self):\n",
    "        self.Player_Type = \"human\"\n",
    "\n",
    "    def Character(self, char):\n",
    "        print(\"\\nNew game!\")\n",
    "\n",
    "    def move(self, board, char):\n",
    "        return int(input(\"Your Move? \"))\n",
    "    \n",
    "    def move_NN(self, board, char):\n",
    "        return int(input(\"Your Move?\"))\n",
    "\n",
    "    def reward(self, value, board):\n",
    "        pass\n",
    "\n",
    "    def available_moves(self, board):\n",
    "        return [i+1 for i in range(0,9) if board[i] == ' ']\n",
    "\n",
    "\n",
    "class Q_Learning_Player(Player):\n",
    "    def __init__(self, epsilon=1, alpha=0.01, gamma=0.9):\n",
    "        self.Player_Type = \"Qlearner\"\n",
    "        self.epsilon = epsilon  ## Exploration Factor\n",
    "        self.alpha = alpha  ## learning Rate\n",
    "        self.gamma = gamma  ## Discount Factor for Future Rewards\n",
    "\n",
    "    def Character(self, char):\n",
    "        self.last_board = (' ',)*9\n",
    "        self.last_move = None\n",
    "\n",
    "    def getQ(self, state, action):\n",
    "        if q.get((state, action)) is None:  ## If (State,Action) pair not present in Q-Table, Initialize to 0 \n",
    "            q[(state, action)] = 0.0\n",
    "        return q.get((state, action))\n",
    "    \n",
    "    def getQ_NN(self, state, action):\n",
    "        State_List=[]\n",
    "        Action=[0] * 9\n",
    "        for Slot in state:\n",
    "            if Slot==' ':\n",
    "                Slot=-1\n",
    "            if Slot=='X':\n",
    "                Slot=0\n",
    "            if Slot=='O':\n",
    "                Slot=1\n",
    "            #print(Slot)\n",
    "            State_List.append(Slot)\n",
    "        Action[action-1]=1\n",
    "        State_Action=State_List+Action\n",
    "        Quality_List=clf.predict(np.array(State_Action).reshape(1,-1))\n",
    "        Quality_List=Quality_List.tolist()\n",
    "        max_value = max(Quality_List)\n",
    "        return max_value\n",
    "        \n",
    "    def move(self, board, char):\n",
    "        if self.Player_Type=='Qlearner' and Print_Winner==True:\n",
    "            print('Q_Learning Player Thinking...')\n",
    "        self.last_board = tuple(board)\n",
    "        actions = self.available_moves(board)\n",
    "\n",
    "        if random.random() < self.epsilon:\n",
    "            self.last_move = random.choice(actions)\n",
    "            return self.last_move\n",
    "\n",
    "        qs = [self.getQ(self.last_board, a) for a in actions]\n",
    "        if char=='X':\n",
    "            maxQ = max(qs)\n",
    "        else:\n",
    "            maxQ = max(qs) # min(qs)\n",
    "\n",
    "        if qs.count(maxQ) > 1:\n",
    "            best_options = [i for i in range(len(actions)) if qs[i] == maxQ]\n",
    "            i = random.choice(best_options)\n",
    "        else:\n",
    "            i = qs.index(maxQ)\n",
    "\n",
    "        self.last_move = actions[i]\n",
    "        return actions[i]\n",
    "    \n",
    "    def move_NN(self, board, char):\n",
    "        if Print_Winner==True:\n",
    "            print('Neural_Network Player Thinking...')\n",
    "        self.last_board = tuple(board)\n",
    "        actions = self.available_moves(board)\n",
    "        qs= [self.getQ_NN(self.last_board, a) for a in actions]\n",
    "        maxQ = max(qs)\n",
    "        if qs.count(maxQ) > 1:\n",
    "            print('Confused')\n",
    "            best_options = [i for i in range(len(actions)) if qs[i] == maxQ]\n",
    "            i = random.choice(best_options)\n",
    "            print(i)\n",
    "        else:\n",
    "            i = qs.index(maxQ)\n",
    "\n",
    "        self.last_move = actions[i]\n",
    "        return actions[i]\n",
    "\n",
    "    def reward(self, value, board):\n",
    "        if self.last_move:\n",
    "            self.learn(self.last_board, self.last_move, value, tuple(board))\n",
    "\n",
    "    def learn(self, state, action, reward, result_state):\n",
    "        prev = self.getQ(state, action)\n",
    "        maxqnew = max([self.getQ(result_state, a) for a in self.available_moves(state)])\n",
    "        q[(state, action)] = prev + self.alpha * ((reward + self.gamma*maxqnew) - prev)\n",
    "        \n",
    "    def reward_intermediate(self,value,board):\n",
    "        if self.last_move:\n",
    "            self.learn_intermediate(self.last_board, self.last_move, value, tuple(board))\n",
    "    \n",
    "    def learn_intermediate(self,state,action,reward,result_state):\n",
    "        prev = self.getQ(state, action)\n",
    "        maxqnew = max([self.getQ(result_state, a) for a in self.available_moves(state)])\n",
    "        q[(state, action)] = prev + self.alpha * ((reward + self.gamma*maxqnew) - prev)\n",
    "\n",
    "\n",
    "p1 = Q_Learning_Player()\n",
    "p2 = Q_Learning_Player()\n",
    "Print_Winner=False\n",
    "q = {} # (state, action) keys: Q values\n",
    "global X_Wins\n",
    "global O_Wins\n",
    "X_Wins=0\n",
    "O_Wins=0\n",
    "Game_Type='Q_Table'\n",
    "\n",
    "Training_Input=input('Train the Q Learner?(Y/N)')\n",
    "if Training_Input=='Y':\n",
    "    Games_Input=input('How Many Games of Self-Play?')\n",
    "    for i in range(1,int(Games_Input)):\n",
    "        Play= TicTacToe(p1, p2)\n",
    "        #p1.epsilon=max(p1.epsilon*0.999,0.02)\n",
    "        #p2.epsilon=max(p2.epsilon*0.999,0.02)\n",
    "        X_Wins,O_Wins=Play.Game(X_Wins,O_Wins,Game_Type)\n",
    "        if i%20000==0:\n",
    "            print(('Iterations: {}, X_Wins: {:0.2f}%, O_Wins: {:0.2f}%, Draws%: {:0.2f}% ').format(i,\n",
    "                                        X_Wins/200,O_Wins/200,100-((X_Wins+O_Wins)/200)))\n",
    "            X_Wins=0\n",
    "            O_Wins=0\n",
    "else:\n",
    "    print('Loading Saved Model...')\n",
    "    pickle_in = open(\"Q_Table.pickle\",\"rb\")\n",
    "    q = pickle.load(pickle_in)\n",
    "\n",
    "p2 = Player()\n",
    "p1.epsilon = 0\n",
    "Print_Winner=True\n",
    "\n",
    "\n",
    "\n",
    "# while True:\n",
    "#     user_input=input('Play Game?(Y,N)')\n",
    "#     if user_input=='N':\n",
    "#         break\n",
    "#    Play= TicTacToe(p1, p2)\n",
    "#     Play.Game(X_Wins,O_Wins,Game_Type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Write Pickle\n",
    "# f = open(\"Q_Table.pickle\",\"wb\")\n",
    "# pickle.dump(q, f)\n",
    "# f.close()\n",
    "# Master=q\n",
    "# del q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75219\n"
     ]
    }
   ],
   "source": [
    "# # Read Pickle\n",
    "# pickle_in = open(\"Q_Table.pickle\",\"rb\")\n",
    "# q = pickle.load(pickle_in)\n",
    "\n",
    "# ## Below This -> Debug\n",
    "# # shared_items = set(Master.items()) & set(q.items())\n",
    "# # print(len(shared_items))\n",
    "print(len(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Play Game?(Y,N)Y\n",
      "\n",
      "New game!\n",
      "   |   |  \n",
      "-----------\n",
      "   |   |  \n",
      "-----------\n",
      "   |   |  \n",
      "Your Move? 5\n",
      "Q_Learning Player Thinking...\n",
      " X |   |  \n",
      "-----------\n",
      "   | O |  \n",
      "-----------\n",
      "   |   |  \n",
      "Your Move? 6\n",
      "Q_Learning Player Thinking...\n",
      " X |   |  \n",
      "-----------\n",
      " X | O | O\n",
      "-----------\n",
      "   |   |  \n",
      "Your Move? 7\n",
      "Q_Learning Player Thinking...\n",
      " X |   | X\n",
      "-----------\n",
      " X | O | O\n",
      "-----------\n",
      " O |   |  \n",
      "Your Move? 2\n",
      "Q_Learning Player Thinking...\n",
      " X | O | X\n",
      "-----------\n",
      " X | O | O\n",
      "-----------\n",
      " O | X |  \n",
      "Your Move? 9\n",
      " X | O | X\n",
      "-----------\n",
      " X | O | O\n",
      "-----------\n",
      " O | X | O\n",
      "Draw!\n",
      "Play Game?(Y,N)N\n"
     ]
    }
   ],
   "source": [
    "## Play Against Q-Learning Player\n",
    "\n",
    "while True:\n",
    "    user_input=input('Play Game?(Y,N)')\n",
    "    if user_input=='N':\n",
    "        break\n",
    "    Play= TicTacToe(p1, p2)\n",
    "    Play.Game(X_Wins,O_Wins,Game_Type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Temp_q=q\n",
    "New_q=[]\n",
    "Y_Train=[]\n",
    "for key in Temp_q:\n",
    "    if Temp_q[key]!=0:\n",
    "        #print(key)\n",
    "        State_Tuple=key[0]\n",
    "        State_List=[]\n",
    "        Action=[0] * 9\n",
    "        for Slot in State_Tuple:\n",
    "            if Slot==' ':\n",
    "                Slot=-1\n",
    "            if Slot=='X':\n",
    "                Slot=0\n",
    "            if Slot=='O':\n",
    "                Slot=1\n",
    "            #print(Slot)\n",
    "            State_List.append(Slot)\n",
    "        Action[key[1]-1]=1\n",
    "        State_Action=State_List+Action\n",
    "        Temp_Y_Multi=Temp_q[key]\n",
    "        New_q.append([State_Action,Temp_Y_Multi])\n",
    "        Y_Train.append(Temp_q[key])\n",
    "        #print(Temp_q[key])\n",
    "# print(New_q,Y_Train)\n",
    "# print(len(New_q))\n",
    "# print(len(Y_Train))\n",
    "training_data=New_q\n",
    "X = np.array([i[0] for i in training_data])\n",
    "Y = [i[1] for i in training_data]\n",
    "# print(Y)\n",
    "# print(Action)\n",
    "# print(len(X[0]))\n",
    "# print(min(Y))\n",
    "# print(max(Y))\n",
    "# print(((Y[0])-min(Y))/(max(Y)-min(Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "Y_Train=np.reshape(Y,(-1,))\n",
    "Y_Train=preprocessing.scale(Y_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.48710978\n",
      "Iteration 2, loss = 0.45886756\n",
      "Iteration 3, loss = 0.42962369\n",
      "Iteration 4, loss = 0.38085323\n",
      "Iteration 5, loss = 0.31995340\n",
      "Iteration 6, loss = 0.27159994\n",
      "Iteration 7, loss = 0.22224577\n",
      "Iteration 8, loss = 0.19003420\n",
      "Iteration 9, loss = 0.16634227\n",
      "Iteration 10, loss = 0.14176514\n",
      "Iteration 11, loss = 0.12250096\n",
      "Iteration 12, loss = 0.10622097\n",
      "Iteration 13, loss = 0.09104919\n",
      "Iteration 14, loss = 0.08279620\n",
      "Iteration 15, loss = 0.07824251\n",
      "Iteration 16, loss = 0.06922519\n",
      "Iteration 17, loss = 0.06155733\n",
      "Iteration 18, loss = 0.05589023\n",
      "Iteration 19, loss = 0.05247630\n",
      "Iteration 20, loss = 0.04878741\n",
      "Iteration 21, loss = 0.04563115\n",
      "Iteration 22, loss = 0.04193824\n",
      "Iteration 23, loss = 0.04047862\n",
      "Iteration 24, loss = 0.03810414\n",
      "Iteration 25, loss = 0.03540294\n",
      "Iteration 26, loss = 0.03305733\n",
      "Iteration 27, loss = 0.03102810\n",
      "Iteration 28, loss = 0.03099878\n",
      "Iteration 29, loss = 0.02960099\n",
      "Iteration 30, loss = 0.02766132\n",
      "Iteration 31, loss = 0.02691896\n",
      "Iteration 32, loss = 0.02603134\n",
      "Iteration 33, loss = 0.02678054\n",
      "Iteration 34, loss = 0.02521428\n",
      "Iteration 35, loss = 0.02430545\n",
      "Iteration 36, loss = 0.02266328\n",
      "Iteration 37, loss = 0.02274096\n",
      "Iteration 38, loss = 0.02328745\n",
      "Iteration 39, loss = 0.02409920\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(325, 325, 325), learning_rate='adaptive',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='adam', tol=1e-05, validation_fraction=0.1, verbose=True,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "clf = MLPRegressor(solver='adam', alpha=1e-3,learning_rate_init=0.001,verbose=True,activation='relu',tol=1e-5,\n",
    "                    hidden_layer_sizes=(325,325,325), random_state=1,learning_rate='adaptive',max_iter=200)\n",
    "clf.fit(X, Y_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # # Write Pickle Neural Network\n",
    "# f = open(\"Neural_Network.pickle\",\"wb\")\n",
    "# pickle.dump(clf, f)\n",
    "# f.close()\n",
    "\n",
    "# # # Load Pickle Neural Network\n",
    "# pickle_in = open(\"Neural_Network.pickle\",\"rb\")\n",
    "# clf = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Play Game?(Y,N)Y\n",
      "\n",
      "New game!\n",
      "   |   |  \n",
      "-----------\n",
      "   |   |  \n",
      "-----------\n",
      "   |   |  \n",
      "Your Move?5\n",
      "Neural_Network Player Thinking...\n",
      " X |   |  \n",
      "-----------\n",
      "   | O |  \n",
      "-----------\n",
      "   |   |  \n",
      "Your Move?7\n",
      "Neural_Network Player Thinking...\n",
      " X |   | X\n",
      "-----------\n",
      "   | O |  \n",
      "-----------\n",
      " O |   |  \n",
      "Your Move?2\n",
      "Neural_Network Player Thinking...\n",
      " X | O | X\n",
      "-----------\n",
      "   | O |  \n",
      "-----------\n",
      " O | X |  \n",
      "Your Move?6\n",
      "Neural_Network Player Thinking...\n",
      " X | O | X\n",
      "-----------\n",
      " X | O | O\n",
      "-----------\n",
      " O | X |  \n",
      "Your Move?9\n",
      " X | O | X\n",
      "-----------\n",
      " X | O | O\n",
      "-----------\n",
      " O | X | O\n",
      "Draw!\n",
      "Play Game?(Y,N)N\n"
     ]
    }
   ],
   "source": [
    "p2 = Player()\n",
    "p1.epsilon = 0\n",
    "Print_Winner=True\n",
    "Game_Type='Neural_Network'\n",
    "while True:\n",
    "    user_input=input('Play Game?(Y,N)')\n",
    "    if user_input=='N':\n",
    "        break\n",
    "    Play= TicTacToe(p1, p2)\n",
    "    Play.Game(X_Wins,O_Wins,Game_Type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96601687976240169"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X,Y_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96608274153626372"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import explained_variance_score\n",
    "explained_variance_score(Y_Train, clf.predict(X), multioutput='uniform_average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.14103745])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(Y_Train, clf.predict(X), multioutput='raw_values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.69087484])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X[0].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 20000, X_Wins: 0.00%, O_Wins: 0.00%, Draws%: 100.00% \n",
      "Iterations: 40000, X_Wins: 0.00%, O_Wins: 0.00%, Draws%: 100.00% \n",
      "Iterations: 60000, X_Wins: 0.00%, O_Wins: 0.00%, Draws%: 100.00% \n",
      "Iterations: 80000, X_Wins: 0.00%, O_Wins: 0.00%, Draws%: 100.00% \n",
      "Iterations: 100000, X_Wins: 0.00%, O_Wins: 0.00%, Draws%: 100.00% \n"
     ]
    }
   ],
   "source": [
    "X_Wins=0\n",
    "O_Wins=0\n",
    "p1 = Q_Learning_Player()\n",
    "p2 = Q_Learning_Player()\n",
    "p1.epsilon=0\n",
    "p1.gamma=0\n",
    "p1.alpha=0\n",
    "p2.epsilon=0\n",
    "p2.gamma=0\n",
    "p2.alpha=0\n",
    "Game_Type='Neural_Network'\n",
    "Print_Winner=False\n",
    "for i in range(1,100001):\n",
    "    Play= TicTacToe(p1, p2)\n",
    "    #p1.epsilon=max(p1.epsilon*0.999,0.02)\n",
    "    #p2.epsilon=max(p2.epsilon*0.999,0.02)\n",
    "    X_Wins,O_Wins=Play.Game(X_Wins,O_Wins,Game_Type)\n",
    "    if i%20000==0:\n",
    "        print(('Iterations: {}, X_Wins: {:0.2f}%, O_Wins: {:0.2f}%, Draws%: {:0.2f}% ').format(i,\n",
    "                                    X_Wins/200,O_Wins/200,100-((X_Wins+O_Wins)/200)))\n",
    "        X_Wins=0\n",
    "        O_Wins=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgcAAAFkCAYAAAC0KZhSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsDiQJEk1/j9AW4AMof+TlwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c06f8c4e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#plt.plot(Y_Train,  color='black')\n",
    "plt.scatter(Y_Train,clf.predict(X), color='blue',\n",
    "         linewidth=0.1)\n",
    "plt.plot([-4,8],[-4,8],color='black')\n",
    "plt.title=\"Predicted Values vs Target values\"\n",
    "plt.xlabel=(\"Targets\")\n",
    "plt.ylabel=(\"Predicted\")\n",
    "plt.savefig('Accuracy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
